install.packages("Rcmdr")
install.packages("FactoMineR")
library(Rcmdr)
detach("package:Rcmdr", unload = TRUE)
library(Rcmdr)
library(Rcmdr)
detach("package:Rcmdr", unload = TRUE)
library(Rcmdr)
library(FactoMineR)
summary(anova_wine_label_odor)
View(wine)
pdf("ANOVA_wine.pdf") # open a pdf file to store the boxplots
for (i in 2:31){
formula_i <- paste(colnames(wine)[i], " ~ Competition") # formula
relating the explanatory and the response variable for each iteration of
the for loop
Boxplot(as.formula(formula_i), data=wine, col=rainbow(7), main =
colnames(wine)[i], ylab= "Result")
print(paste("Summary of: ", colnames(wine)[i], " ~ Competition:")) #
print this as the title for each summary
print(summary(aov(as.formula(formula_i), data=wine)))
}
dev.off() # close the pdf file
pdf("ANOVA_wine.pdf")
for (i in 2:31){
formula_i <- paste(colnames(wine)[i], " ~ Competition")
Boxplot(as.formula(formula_i), data=wine, col=rainbow(7), main =colnames(wine)[i], ylab= "Result")
print(paste("Summary of: ", colnames(wine)[i], " ~ Competition:"))
print(summary(aov(as.formula(formula_i), data=wine)))
}
dev.off() # close the pdf file
pdf("ANOVA_wine.pdf")
for (i in 2:31){
formula_i <- paste(colnames(wine)[i], " ~ Label")
Boxplot(as.formula(formula_i), data=wine, col=rainbow(7), main =colnames(wine)[i], ylab= "Result")
print(paste("Summary of: ", colnames(wine)[i], " ~ Label:"))
print(summary(aov(as.formula(formula_i), data=wine)))
}
dev.off()
pdf("ANOVA_wine.pdf")
for (i in 2:31){
formula_i <- paste(colnames(wine)[i], " ~ Label")
Boxplot(as.formula(formula_i), data=wine, col=rainbow(7), main =colnames(wine)[i], ylab= "Result")
print(paste("Summary of: ", colnames(wine)[i], " ~ Label:"))
print(summary(aov(as.formula(formula_i), data=wine)))
}
dev.off()
source('~/UPC/Semester 1/SMDE/Assignment1/Q2/wine_script.R')
for (i in 3:31){
formula_i <- paste(colnames(wine)[i], " ~ Label")
Boxplot(as.formula(formula_i), data=wine, col=rainbow(7), main =colnames(wine)[i], ylab= "Result")
print(paste("Summary of: ", colnames(wine)[i], " ~ Label:"))
print(summary(aov(as.formula(formula_i), data=wine)))
}
dev.off()
pdf("ANOVA_wine.pdf")
for (i in 3:31){
formula_i <- paste(colnames(wine)[i], " ~ Label")
Boxplot(as.formula(formula_i), data=wine, col=rainbow(7), main =colnames(wine)[i], ylab= "Result")
print(paste("Summary of: ", colnames(wine)[i], " ~ Label:"))
print(summary(aov(as.formula(formula_i), data=wine)))
}
dev.off()
pdf("ANOVA_wine.pdf")
for (i in 3:31){
formula_i <- paste(colnames(wine)[i], " ~ Label")
Boxplot(as.formula(formula_i), data=wine, col=rainbow(7), main =colnames(wine)[i], ylab= "Result")
print(paste("Summary of: ", colnames(wine)[i], " ~ Label:"))
print(summary(aov(as.formula(formula_i), data=wine)))
}
dev.off()
source('~/UPC/Semester 1/SMDE/Assignment1/Q2/wine_script.R')
source('~/UPC/Semester 1/SMDE/Assignment1/Q2/wine_script.R')
source('~/UPC/Semester 1/SMDE/Assignment1/Q2/wine_script.R')
source('~/UPC/Semester 1/SMDE/Assignment1/Q2/wine_script.R')
source('~/UPC/Semester 1/SMDE/Assignment1/Q2/wine_script.R')
source('~/UPC/Semester 1/SMDE/Assignment1/Q2/ANOVA_ASSUMPTIONS_SCRIPT.R')
source('~/UPC/Semester 1/SMDE/Assignment1/Q2/ANOVA_ASSUMPTIONS_SCRIPT.R')
source('~/UPC/Semester 1/SMDE/Assignment1/Q2/ANOVA_ASSUMPTIONS_SCRIPT.R')
source('~/UPC/Semester 1/SMDE/Assignment1/Q2/ANOVA_ASSUMPTIONS_SCRIPT.R')
library("lmtest", lib.loc="~/R/win-library/3.0")
dwtest(aov(Odor.Intensity.before.shaking ~ Label, data=wine))
#The populations from which the samples are selected must be normal.
#Shapiro test
shapiro.test(residuals(aov(Odor.Intensity.before.shaking ~ Label, data=wine)))
#The populations from which the samples are selected must have equal variances (homogeneity of variance)
#Breusch Pagan test
lmtest::bptest(aov(Odor.Intensity.before.shaking ~ Label, data=wine))
library("lmtest", lib.loc="~/R/win-library/3.0")
dwtest(aov(Odor.Intensity ~ Label, data=wine))
#The populations from which the samples are selected must be normal.
#Shapiro test
shapiro.test(residuals(aov(Odor.Intensity ~ Label, data=wine)))
#The populations from which the samples are selected must have equal variances (homogeneity of variance)
#Breusch Pagan test
lmtest::bptest(aov(Odor.Intensity ~ Label, data=wine))
library("lmtest", lib.loc="~/R/win-library/3.0")
dwtest(aov(Odor.Intensity ~ Label, data=wine))
#The populations from which the samples are selected must be normal.
#Shapiro test
shapiro.test(residuals(aov(Odor.Intensity ~ Label, data=wine)))
#The populations from which the samples are selected must have equal variances (homogeneity of variance)
#Breusch Pagan test
lmtest::bptest(aov(Odor.Intensity ~ Label, data=wine))
#The observations within each sample must be independent.
#Durbin Watson
library("lmtest", lib.loc="~/R/win-library/3.0")
dwtest(aov(Phenolic ~ Label, data=wine))
#The populations from which the samples are selected must be normal.
#Shapiro test
shapiro.test(residuals(aov(Phenolic ~ Label, data=wine)))
#The populations from which the samples are selected must have equal variances (homogeneity of variance)
#Breusch Pagan test
lmtest::bptest(aov(Phenolic ~ Label, data=wine))
library(qDapDictionaries)
library(qdapDictionaries)
install.packages(qdapDictionaries)
install.packages("qdapDictionaries")
library(qdapDictionaries)
qdapDictionaries::negation.words
# Libraries
require(data.table)
require(bit64)
require(dbscan)
require(doParallel)
require(dplyr)
update.packages(ask=FALSE)
update.packages(ask=FALSE)
library(boot, lib.loc = "C:/Program Files/R/R-4.0.1/library")
library(class, lib.loc = "C:/Program Files/R/R-4.0.1/library")
library(cluster, lib.loc = "C:/Program Files/R/R-4.0.1/library")
%>% mutate(tracklet = Reduce(paste, layer, 4))
tracklets <- data.table(hits[order(col, z)] %>% group_by(col)
%>% mutate(tracklet = Reduce(paste, layer, 4)))
# Libraries
require(data.table)
require(bit64)
require(dbscan)
require(doParallel)
require(dplyr)
require(rBayesianOptimization)
require(plotly)
require(DescTools)
require(viridis)
require(tidyr)
setwd("~/UPC/Semester 2/ML/project/code")
# Libraries
require(data.table)
require(bit64)
require(dbscan)
require(doParallel)
require(dplyr)
require(rBayesianOptimization)
require(plotly)
require(DescTools)
require(viridis)
require(tidyr)
score <- function(labelled, truth) {
tmp = merge(labelled, truth[,.(hit_id, particle_id, weight)])
tmp[, Np:=.N, by=particle_id]
tmp[, Nt:=.N, by=track_id]
tmp[, Ntp:=.N, by=list(track_id, particle_id)]
tmp[, r1:=Ntp/Nt]
tmp[, r2:=Ntp/Np]
sum(tmp[r1>0.5 & r2 > 0.5, weight])
}
cluster_transformML <- function(path, w1, w2, w3, w4, w5, w6, n_iters, ep){
# Read hits data
# Transform initial hit coords to helix parameters, for use by dbscan
# Helix params are invariant for points on helix, so dbscan will cluster them.
hits = data.table(read.csv(paste0(path, "-hits.csv"), header=TRUE, sep=","))
hits[, r:=sqrt(x*x+y*y+z*z)]
hits[, rt:=sqrt(x*x+y*y)]
hits[, a0:=atan2(y, x)]
hits[, ydivr:=y/r]
hits[, xdivr:=x/r]
mm     <-  1
# Loop for n_iters
for (ii in 0:n_iters) {
# Helix goes either direction
mm <- mm*(-1)
# Calculate transformed coords
hits[, dtheta:=mm*(rt+0.000005*rt^2)/1000*(ii/2)/180*pi]
hits[, theta_ratio:= 1 - (abs(z + 200) / 6000)**2.4 + 0.005]
hits[, a1:=a0+dtheta*theta_ratio]
hits[, zdivrt:=z/rt]
hits[, zdivr:=z/r]
# Use robust params
hits[,sina1:=sin(a1)]
hits[,cosa1:=cos(a1)]
# Scale data
scaled=scale(hits[,.(sina1,cosa1,zdivrt,zdivr, xdivr, ydivr)])
weights <- c(w1, w2, w3, w4, w5, w6)
for (jj in 1:ncol(scaled)) scaled[,jj] <- scaled[,jj]*weights[jj]
# Do clustering
clusts=dbscan(scaled,eps=ep,minPts = 1)
# If initial run, just label each hit to a track
# and count track populations
if (ii==0) {
hits[,track_id:=clusts$cluster]
hits[,N1:=.N, by=track_id]
}else{
print(ii)
# Find unique large number
maxs1 <- max(hits$track_id)
# label each hit to a new_track
# count each new_track volumes
hits[,s2:=clusts$cluster]
hits[,N2:=.N, by=s2]
#tmp <- hits %>% group_by(s2)) %>%
#hits <- hits %>% group_by(s2) %>%  summarise(NVOLS = n_distinct(paste(volume_id, layer_id, module_id)))
#hits[,N2:=uniqueN(paste(volume_id, layer_id, module_id)), by=s2]
# If the old_track population is less than the new_track population,
# and the new_track is less than 20, then relabel hit to new_track using unique id
hits[,track_id:=ifelse(N2>N1 & N2<20,s2+maxs1,track_id)]
hits[,track_id:=as.integer(as.factor(track_id))]
# Count new population
hits[,N1:=.N, by=track_id]
}
}
return(hits)
}
n_event = 1001
path = paste0("C:/Users/jaked/OneDrive/Documents/UPC/Semester 2/ML/project/data/train_1/event00000", n_event)
truth = data.table(read.csv(paste0(path, "-truth.csv"), header=TRUE, sep=","))
print("Clustering")
clustered <- cluster_transformML(path,
w1=3.0, w2=3.0, w3=1.0, w4=0.2521, w5=0.0211, w6=0.0474,
n_iters = 30,
ep = 0.0088)
tracklets <- data.table(clustered[order(col, z)] %>% group_by(col)
%>% mutate(tracklet = Reduce(paste, layer, 4)))
tracklets <- data.table(clustered[order(s2, z)] %>% group_by(s2)
%>% mutate(tracklet = Reduce(paste, layer, 4)))
View(tracklets)
tracklets <- data.table(clustered[order(s2, z)] %>% group_by(s2)
%>% mutate(tracklet = Reduce(paste,shift(layer, 1))))
tracklets <- data.table(clustered[order(s2, z)] %>% group_by(s2)
%>% mutate(tracklet = Reduce(paste,shift(layer, 0)) ))
rlang::last_error()
tracklets <- data.table(clustered[order(s2, z)] %>% group_by(s2)
%>% mutate(tracklet = Reduce(paste,shift(layer, c(0))) ))
tmp <- clustered[, tracklet:=frollapply(layer, 4, f), by=s2]
f <- function(x) paste(x, collapse="  ")
tmp <- clustered[, tracklet:=frollapply(layer, 4, f), by=s2]
tracklets <- data.table(clustered[order(s2, z)] %>% group_by(s2)
%>% mutate(tracklet = Reduce(paste,shift(layer, c(0))) ))
tracklets <- data.table(clustered[order(s2, z)] %>% group_by(s2)
%>% mutate(paste, layer, collapse= "  "))
View(clustered)
# layer quality
clustered[, layer:=100*volume_id + layer_id]
tracklets <- data.table(clustered[order(s2, z)] %>% group_by(s2)
%>% mutate(paste, layer, collapse= "  "))
tracklets <- data.table(clustered[order(s2, z)] %>% group_by(s2)
%>% mutate(tracklet = paste(layer, collapse= "  ")))
View(tracklets)
